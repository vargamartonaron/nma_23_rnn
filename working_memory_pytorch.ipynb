{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPs8jMt69lXEiQK/Go5wbUF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vargamartonaron/nma_23_rnn/blob/main/working_memory_pytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y2lUoh2B8QbE"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "\n",
        "# Set the random seed for reproducibility\n",
        "torch.manual_seed(42)\n",
        "\n",
        "# RNN model definition\n",
        "class WorkingMemoryRNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        super(WorkingMemoryRNN, self).__init__()\n",
        "        self.rnn = nn.RNN(input_size, hidden_size, nonlinearity='tanh', batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        h0 = torch.zeros(1, x.size(0), self.rnn.hidden_size).to(x.device)\n",
        "        out, _ = self.rnn(x, h0)\n",
        "        out = self.fc(out[:, -1, :])\n",
        "        return out\n",
        "\n",
        "def generate_ou_input_data(batch_size, input_size, sequence_length, theta=0.15, mu=0.0, sigma=0.3):\n",
        "    ou_inputs = np.zeros((batch_size, sequence_length, input_size))\n",
        "    for i in range(batch_size):\n",
        "        for j in range(input_size):\n",
        "            x = np.zeros(sequence_length)\n",
        "            x[0] = np.random.randn()  # Initial value\n",
        "            for t in range(1, sequence_length):\n",
        "                x[t] = x[t - 1] + theta * (mu - x[t - 1]) + sigma * np.random.randn()\n",
        "            ou_inputs[i, :, j] = x\n",
        "\n",
        "    return torch.tensor(ou_inputs, dtype=torch.float32)\n",
        "\n",
        "# Set the parameters for the RNN model\n",
        "input_size = 20\n",
        "hidden_size = 1000\n",
        "output_size = 20\n",
        "\n",
        "# Corrected sequence length\n",
        "sequence_length = hidden_size + output_size - 2\n",
        "\n",
        "# Create the RNN model\n",
        "model = WorkingMemoryRNN(input_size, hidden_size, output_size)\n",
        "\n",
        "# Set the loss function and optimizer\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Training loop (using synthetic OU data for demonstration)\n",
        "num_epochs = 1000\n",
        "batch_size = 32\n",
        "\n",
        "# Generate synthetic OU input data with the correct sequence length\n",
        "ou_data = generate_ou_input_data(batch_size, input_size, sequence_length)\n",
        "\n",
        "# Corrected output size (excluding the last two time steps)\n",
        "output_size = sequence_length - 2\n",
        "\n",
        "# Train the model\n",
        "for epoch in range(num_epochs):\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # Generate input data for the current epoch\n",
        "    inputs = ou_data.clone()\n",
        "\n",
        "    # Shift input data by 2 timesteps to create the previous two timesteps prediction task\n",
        "    inputs_shifted = torch.cat((inputs[:, :-2, :], torch.zeros(batch_size, 2, input_size)), dim=1)\n",
        "\n",
        "    # Generate the ground truth output for the previous two timesteps prediction task\n",
        "    ground_truth = inputs[:, 2:2+output_size, :]  # Adjusted to have the correct sequence length\n",
        "\n",
        "    # Initialize the loss accumulator\n",
        "    total_loss = 0.0\n",
        "\n",
        "    # Iterate through each time step for the current sequence\n",
        "    for t in range(output_size):\n",
        "        # Forward pass for the current time step\n",
        "        output_t = model(inputs_shifted[:, t:t+2, :])\n",
        "\n",
        "        # Compute the loss for the current time step\n",
        "        loss_t = criterion(output_t, ground_truth[:, t, :])\n",
        "\n",
        "        # Accumulate the loss\n",
        "        total_loss += loss_t\n",
        "\n",
        "    # Average the losses and backpropagate\n",
        "    total_loss /= output_size\n",
        "    total_loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if (epoch + 1) % 100 == 0:\n",
        "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {total_loss.item():.4f}')\n",
        "\n",
        "# Evaluation\n",
        "model.eval()\n",
        "\n",
        "# Generate new input data for evaluation\n",
        "eval_inputs = generate_ou_input_data(batch_size, input_size, sequence_length)\n",
        "\n",
        "# Create empty tensors to store the predicted outputs and inferred inputs\n",
        "eval_outputs_pred = torch.zeros(batch_size, output_size, hidden_size)\n",
        "inferred_inputs_t = torch.zeros(batch_size, output_size, input_size)\n",
        "inferred_inputs_t_minus_1 = torch.zeros(batch_size, output_size, input_size)\n",
        "inferred_inputs_t_minus_2 = torch.zeros(batch_size, output_size, input_size)\n",
        "\n",
        "# Iterate through each timestep for the evaluation task\n",
        "for t in range(output_size):\n",
        "    # Slice the input data for the current timestep\n",
        "    eval_inputs_t = eval_inputs[:, :t+1, :]  # Include the current timestep and all previous timesteps\n",
        "\n",
        "    # Shift input data by 2 timesteps for the evaluation task\n",
        "    eval_inputs_t_shifted = torch.cat((eval_inputs_t[:, :-2, :], torch.zeros(batch_size, 2, input_size)), dim=1)\n",
        "\n",
        "    # Forward pass for evaluation\n",
        "    eval_outputs_t = model(eval_inputs_t_shifted)\n",
        "\n",
        "    # Store the predicted outputs for the current timestep\n",
        "    eval_outputs_pred[:, t, :] = eval_outputs_t[:, -1, :]\n",
        "\n",
        "    # Infer the inputs at t-1 and t-2 from the current output\n",
        "    if t > 1:\n",
        "        inferred_inputs_t[:, t-1, :] = eval_outputs_t[:, -2, :]\n",
        "    if t > 0:\n",
        "        inferred_inputs_t_minus_1[:, t-2, :] = eval_outputs_t[:, -3, :]\n",
        "    if t > 2:\n",
        "        inferred_inputs_t_minus_2[:, t-3, :] = eval_outputs_t[:, -4, :]\n",
        "\n",
        "# Reshape both tensors to have the same shape (flatten the last two dimensions)\n",
        "outputs = eval_outputs_pred.reshape(batch_size * output_size, hidden_size)\n",
        "ground_truth_t = eval_inputs[:, 2:2+output_size, :].reshape(batch_size * output_size, input_size)\n",
        "ground_truth_t_minus_1 = eval_inputs[:, 1:1+output_size, :].reshape(batch_size * output_size, input_size)\n",
        "ground_truth_t_minus_2 = eval_inputs[:, :output_size, :].reshape(batch_size * output_size, input_size)\n",
        "\n",
        "# Compute accuracy for inferring the inputs at each timestep\n",
        "accuracy_t = (inferred_inputs_t.argmax(dim=2) == ground_truth_t.argmax(dim=1)).float().mean().item()\n",
        "accuracy_t_minus_1 = (inferred_inputs_t_minus_1.argmax(dim=2) == ground_truth_t_minus_1.argmax(dim=1)).float().mean().item()\n",
        "accuracy_t_minus_2 = (inferred_inputs_t_minus_2.argmax(dim=2) == ground_truth_t_minus_2.argmax(dim=1)).float().mean().item()\n",
        "\n",
        "print(\"Accuracy for inferring input at timestep t:\", accuracy_t)\n",
        "print(\"Accuracy for inferring input at timestep t-1:\", accuracy_t_minus_1)\n",
        "print(\"Accuracy for inferring input at timestep t-2:\", accuracy_t_minus_2)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "outputs.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IreNwnhINGJC",
        "outputId": "4d1825e1-11b8-44b1-f89d-0997d220ae88"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([32, 20])"
            ]
          },
          "metadata": {},
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ground_truth.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6GB1krvGNIr-",
        "outputId": "62ad8de6-d326-4ca1-b56d-898e83aa112a"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([32, 18, 20])"
            ]
          },
          "metadata": {},
          "execution_count": 86
        }
      ]
    }
  ]
}